{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce47787",
   "metadata": {
    "id": "8aab069b"
   },
   "source": [
    "# Streaming \n",
    "In this exercise we want to test our keyword spotter on self recorded wav files containing some keywords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83218c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import *\n",
    "from utility import smoothing, augment_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25aa0a",
   "metadata": {},
   "source": [
    "### Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c5e52",
   "metadata": {
    "id": "76a09bd2"
   },
   "outputs": [],
   "source": [
    "## Load a pretrained model, you should choose a good one here out of the ones you have trained\n",
    "checkpoint_path = './output/2022_05_02_13_29_15/saved_models/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a947ff",
   "metadata": {
    "id": "76a09bd2"
   },
   "outputs": [],
   "source": [
    "## Load the model\n",
    "if os.path.isdir(checkpoint_path):\n",
    "    model = tf.keras.models.load_model(checkpoint_path)\n",
    "    print('model loaded successfully')\n",
    "else:\n",
    "    print('could not find model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38bde8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of trained model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42738b",
   "metadata": {},
   "source": [
    "### Deployment of keyword spotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10221b28",
   "metadata": {
    "id": "ac42b85e"
   },
   "outputs": [],
   "source": [
    "## Applying the kws to a given 1s audio chunk of data and returns a dictionary with the calculated scores\n",
    "def apply_spotter(data=[], model=model):\n",
    "    assert len(data)==fs\n",
    "    mfccs = augment_audio(mode='',sig=data, fs=fs, l=l, s=s, n_mfccs=n_mfccs).reshape(1,49,40)\n",
    "    prediction = model.predict(mfccs)[0]\n",
    "    return {k:prediction[i] for i,k in enumerate(kws_all)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f963c",
   "metadata": {
    "id": "9c50f532"
   },
   "outputs": [],
   "source": [
    "## Load a recording containing some keywords. I provided this one but its more fun to try on your own recording\n",
    "## I said: yes, no, what am I doing, go with short breaks in between\n",
    "path_to_recording = './media/test.wav'\n",
    "\n",
    "audio = librosa.load(path_to_recording, sr=16000)[0]\n",
    "ipd.Audio(audio, rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61cd8fd",
   "metadata": {
    "id": "568efd5b"
   },
   "outputs": [],
   "source": [
    "## Divide the stream into chunks to simulate real streaming\n",
    "chunksize = 4000\n",
    "\n",
    "audio_chunked = np.array([ audio[i*chunksize:(i+1)*chunksize] for i in range(0,len(audio)//chunksize)] )\n",
    "audio_chunked.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8666e5",
   "metadata": {
    "id": "1ff7ea38"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "1. Create a $1s$ long audio array. For each chunk in audio_chunked, update the $1s$ long audio array and pass it to the apply_spotter function to evaluate the keyword spotter. Save the resulting probability scores into a vector \"all_scores\". Each entry of \"all_scores\" should contain $12$ probabilities, one for each keyword.\n",
    "2. Plot the probabilities for all classes over time. How would you decide when a keyword was said based on the scores?\n",
    "3. Understand what the smoothing function above does and use it to smooth the \"all_scores\" vector. Visualize the smoothed results. Are they better? Why?\n",
    "4. Execute the notebook again, but with your own recording. You can use **audacity** to create a $.wav$ file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e7750",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "- Think about how you need to adjust the $1s$ long audio snippet each time a new chunk arrives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb673edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Image('./media/streaming_kws.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b1f79",
   "metadata": {
    "id": "7f292022"
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9552ef",
   "metadata": {
    "id": "cc53e92a"
   },
   "source": [
    "### E1\n",
    "\n",
    "We drop the oldest chunk (left part of the input vector) and append the new chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025008ac",
   "metadata": {
    "id": "b1963db2"
   },
   "outputs": [],
   "source": [
    "## Apply the model to the audio stream\n",
    "audio_1s = np.zeros(16000)\n",
    "all_scores = []\n",
    "\n",
    "for chunk in audio_chunked:\n",
    "    \n",
    "    ## Throw out the oldest chunk\n",
    "    audio_1s[0:16000-chunksize] = audio_1s[chunksize:]\n",
    "    \n",
    "    ## Append the latest chunk\n",
    "    audio_1s[16000-chunksize:] = chunk\n",
    "    \n",
    "    ## Apply the spotter\n",
    "    scores = apply_spotter(audio_1s)\n",
    "    \n",
    "    ## Save scores for plotting\n",
    "    all_scores.append([scores[key] for key in scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ff845",
   "metadata": {
    "id": "8bfc064b"
   },
   "source": [
    "### E2 &  E3\n",
    "We use a threshold whose value balances between false positives and false negatives. The problem is, there are some high but small width peaks that are obviously wrong. To avoid a false positive we also use the width of the peaks to decide wether a keyword was spoken. For example, this can  be done by using the area under the curve over a fixed amount of past time frames. The result (fig. 2) shows, that the narrow peaks can now be avoided by choosing a sufficiently high threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9829c",
   "metadata": {
    "id": "c6cecb5e"
   },
   "outputs": [],
   "source": [
    "## plot the output probabilities\n",
    "smoothing_level = 4\n",
    "\n",
    "colors = ['red', 'green', 'blue', 'black', 'orange', 'brown', 'yellow', 'red', 'green', 'blue', 'black']\n",
    "lines = [\"-\", \"--\", \"-.\", \":\", \"-\", \"--\", \"-.\", \":\", \"-\", \"--\", \"-.\", \":\", \"-\", \"--\", \"-.\", \":\"]\n",
    "\n",
    "fig, axs = plt.subplots(2,)\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "hw_prob_smoothed = np.array(all_scores)\n",
    "\n",
    "for i in range(len(hw_prob_smoothed[0])):\n",
    "    axs[0].plot(hw_prob_smoothed[:,i], linestyle=lines[i])\n",
    "    axs[0].axhline(y=.7, color='r')    \n",
    "    \n",
    "    axs[1].plot(smoothing(hw_prob_smoothed, smoothing_level)[:,i], label=kws_all[i], linestyle=lines[i])\n",
    "    axs[1].axhline(y=.55, color='r')    \n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad51c4",
   "metadata": {
    "id": "b282539a"
   },
   "outputs": [],
   "source": [
    "ipd.Audio(audio, rate=16000)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "8aab069b"
   ],
   "name": "Kopie von 00_all_in_one_kws.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
