{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c348236",
   "metadata": {},
   "source": [
    "# Neural networks for audio classification\n",
    "\n",
    "## Part 3: Model Training\n",
    "\n",
    "We will train a classifier (neural network) that predicts which keyword or class is present from the MFCC features of a one-second long audio clip."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a4f77-44a1-49b1-b23e-3d667db95f3d",
   "metadata": {},
   "source": [
    "### Load some libs and setup GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94193695-446f-4bb2-a77d-157025af7eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51eac493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no gpus found!\n"
     ]
    }
   ],
   "source": [
    "## Activate gpu usage if available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:    \n",
    "    try:  \n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('no gpus found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06ed9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ceaf3d",
   "metadata": {
    "id": "herbal-gentleman"
   },
   "outputs": [],
   "source": [
    "from config import *\n",
    "import pandas as pd\n",
    "from utility import keep_only_n_unknowns, pad_signal, augment_audio, get_callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d52b8d-ca38-4fc4-be36-7fd7275e1407",
   "metadata": {},
   "source": [
    "### Setup our first neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db62106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features have the dimension: 49 x 40 and output neurons: 12\n"
     ]
    }
   ],
   "source": [
    "## Infer model size\n",
    "n_max_frames     =  49  # leave this at 49 \n",
    "n_output_neurons = 12\n",
    "\n",
    "\n",
    "print('features have the dimension:', n_max_frames, 'x', n_mfccs, 'and output neurons:', n_output_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeee620",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "We will use `tf.keras.models.Sequential(list_of_layers)` and feed a list of layers to it to create our model. \n",
    "\n",
    "1. Create a feed forward network with $2$ hidden layers and **ReLU** activation functions, that has a softmax output layer. you can use `tf.keras.Input()` as the input layer before the Dense hidden layers. Use $64$, $128$ neurons for your **\"Dense\"** layers. The input dimension is the dimension of the spectrogram image, aka $(49 x 40)$. A hidden layer only accepts $1$ dimensional input. You could use the **reshape** layer to reshape the input from (49,40) to (49*40), which is now only $1$ dimensional.\n",
    "\n",
    "2. Check the dimensions and parameters of your model using `model.summary()` and try out the `model.predict` function on a training batch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479fded",
   "metadata": {},
   "source": [
    "## Hints:\n",
    "1. \n",
    "Here is a blueprint: \n",
    "\n",
    "```\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(name='input_layer', shape=(\"xxx\", \"yyy\")),\n",
    "        layers.Reshape((\"xxx\" * \"yyy\", ), input_shape=(\"xxx\", \"yyy\")),\n",
    "        layers.Dense(\"\", activation='relu'),\n",
    "        layers.Dense(\"\", activation='relu'),\n",
    "        layers.Dense(\"\", activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "2. You can use `np.random.random()` and pass it a tuple of $(batchsize, 49, 40)$ to create a random batch for testing the model with the `model.predict()` function.\n",
    "\n",
    "3. The predictions should sum up to $1$ because we have used a **Softmax** layer. You can check it with np.sum(prediction_vector)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf27f1c0",
   "metadata": {},
   "source": [
    "## Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b33239",
   "metadata": {},
   "source": [
    "### E1\n",
    "Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c38b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(name='input_layer', shape=(n_max_frames, n_mfccs)),\n",
    "        layers.Reshape((n_max_frames * n_mfccs, ), input_shape=(n_max_frames, n_mfccs)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(n_output_neurons, activation='softmax'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2f59ff",
   "metadata": {},
   "source": [
    "### E2\n",
    "Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da27d11c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a9c4d88",
    "outputId": "46a7a22a-d169-4980-fa96-3920962e30ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 1960)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                125504    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135,372\n",
      "Trainable params: 135,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 49, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f699ef",
   "metadata": {},
   "source": [
    "Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74111b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08838195 0.08457235 0.0447917  0.05025874 0.02020248 0.10175817\n",
      " 0.1082058  0.1439389  0.11919267 0.05784237 0.1036185  0.07723636] \n",
      " sum: 0.99999994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "prediction = model.predict(np.random.random((10,49,40)))[0]\n",
    "print(prediction, '\\n sum:', np.sum(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf4f34",
   "metadata": {
    "id": "painted-kidney"
   },
   "source": [
    "# Part 4: Train the model\n",
    "\n",
    "In this part, we will compile the model by providing loss, metrics and an optimizer. We will use one set of parameters for the following trainings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f614c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of epochs to run the training for\n",
    "n_epochs= 30\n",
    "\n",
    "## Early stopping setting\n",
    "patience= 25    \n",
    "\n",
    "## Logging/debugging \n",
    "debugging_mode = False\n",
    "\n",
    "## size of the batches used in training\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c93e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile the model\n",
    "from tensorflow import keras\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy()],\n",
    "              run_eagerly=debugging_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cb8c8b",
   "metadata": {},
   "source": [
    "## Fit with training set unaugmented 1fold\n",
    "Now we finally get to training a model. Keras has everything implemented inside the model class. While it is possible to write a custom training, we can just pass all the options to the `model.fit()` function and it will do everything for us. We need to pass:\n",
    "- Training set as $x$ and $y$.\n",
    "- **steps_per_epoch**, which are the number of batches inside the training set.\n",
    "- **n_epochs**, which is the total number of epochs to train for.\n",
    "- **Shuffle**, which automatically shuffles the dataset after each epoch (we set it to **False** for now for all our trainings).\n",
    "- **validation_data**, which is the validation set. This will only be used to calculate loss and accuracy on itself.\n",
    "- Callbacks, which is a collection of methods that are called throughout the training. We have provided a callback function for you that will write out certain metrics like **confusion matrix**, **roc curve** and so on. You should check if you can find those in your output_dir, sorted by the datetime when the training started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c6e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "\n",
    "importlib.reload(sys.modules['utility'])\n",
    "from utility import get_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "858f67cb-a0ad-4a85-bb51-c39e02227071",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"./data/X_train_data.npy\"), np.load(\"./data/Y_train_data.npy\")\n",
    "val_data = np.load(\"./data/X_val_data.npy\"), np.load(\"./data/Y_val_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d69ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging to:  ./output/2023_07_26_22_08_11/\n",
      "Epoch 1/30\n",
      "1162/1162 [==============================] - ETA: 0s - loss: 3.0449 - categorical_accuracy: 0.3504"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 22:08:21.715866: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./output/2023_07_26_22_08_11/saved_models/assets\n",
      "1162/1162 [==============================] - 18s 14ms/step - loss: 3.0449 - categorical_accuracy: 0.3504 - val_loss: 1.6105 - val_categorical_accuracy: 0.4470\n",
      "Epoch 2/30\n",
      "1162/1162 [==============================] - ETA: 0s - loss: 1.5841 - categorical_accuracy: 0.4503INFO:tensorflow:Assets written to: ./output/2023_07_26_22_08_11/saved_models/assets\n",
      "1162/1162 [==============================] - 23s 20ms/step - loss: 1.5841 - categorical_accuracy: 0.4503 - val_loss: 1.5213 - val_categorical_accuracy: 0.4776\n",
      "Epoch 3/30\n",
      "1162/1162 [==============================] - 9s 7ms/step - loss: 1.5056 - categorical_accuracy: 0.4763 - val_loss: 1.4751 - val_categorical_accuracy: 0.4750\n",
      "Epoch 4/30\n",
      "1161/1162 [============================>.] - ETA: 0s - loss: 1.4706 - categorical_accuracy: 0.4886INFO:tensorflow:Assets written to: ./output/2023_07_26_22_08_11/saved_models/assets\n",
      "1162/1162 [==============================] - 16s 14ms/step - loss: 1.4704 - categorical_accuracy: 0.4886 - val_loss: 1.4576 - val_categorical_accuracy: 0.4927\n",
      "Epoch 5/30\n",
      "1160/1162 [============================>.] - ETA: 0s - loss: 1.4033 - categorical_accuracy: 0.5142INFO:tensorflow:Assets written to: ./output/2023_07_26_22_08_11/saved_models/assets\n",
      "1162/1162 [==============================] - 14s 12ms/step - loss: 1.4031 - categorical_accuracy: 0.5142 - val_loss: 1.4721 - val_categorical_accuracy: 0.5064\n",
      "Epoch 6/30\n",
      "1153/1162 [============================>.] - ETA: 0s - loss: 1.4351 - categorical_accuracy: 0.5148INFO:tensorflow:Assets written to: ./output/2023_07_26_22_08_11/saved_models/assets\n",
      "1162/1162 [==============================] - 9s 8ms/step - loss: 1.4348 - categorical_accuracy: 0.5148 - val_loss: 1.4536 - val_categorical_accuracy: 0.5162\n",
      "Epoch 7/30\n",
      "1158/1162 [============================>.] - ETA: 0s - loss: 1.2964 - categorical_accuracy: 0.5515INFO:tensorflow:Assets written to: ./output/2023_07_26_22_08_11/saved_models/assets\n",
      "1162/1162 [==============================] - 10s 9ms/step - loss: 1.2973 - categorical_accuracy: 0.5513 - val_loss: 1.4850 - val_categorical_accuracy: 0.5182\n",
      "Epoch 8/30\n",
      "1159/1162 [============================>.] - ETA: 0s - loss: 1.2218 - categorical_accuracy: 0.5731INFO:tensorflow:Assets written to: ./output/2023_07_26_22_08_11/saved_models/assets\n",
      "1162/1162 [==============================] - 12s 10ms/step - loss: 1.2211 - categorical_accuracy: 0.5733 - val_loss: 1.2732 - val_categorical_accuracy: 0.5758\n",
      "Epoch 9/30\n",
      "1162/1162 [==============================] - 13s 11ms/step - loss: 1.1600 - categorical_accuracy: 0.5930 - val_loss: 1.2634 - val_categorical_accuracy: 0.5623\n",
      "Epoch 10/30\n",
      "1162/1162 [==============================] - ETA: 0s - loss: 1.0998 - categorical_accuracy: 0.6123INFO:tensorflow:Assets written to: ./output/2023_07_26_22_08_11/saved_models/assets\n",
      "1162/1162 [==============================] - 10s 8ms/step - loss: 1.0998 - categorical_accuracy: 0.6123 - val_loss: 1.2137 - val_categorical_accuracy: 0.5929\n",
      "Epoch 11/30\n",
      "1162/1162 [==============================] - 11s 10ms/step - loss: 1.0720 - categorical_accuracy: 0.6240 - val_loss: 1.1915 - val_categorical_accuracy: 0.5924\n",
      "Epoch 12/30\n",
      "1162/1162 [==============================] - ETA: 0s - loss: 1.0185 - categorical_accuracy: 0.6422INFO:tensorflow:Assets written to: ./output/2023_07_26_22_08_11/saved_models/assets\n",
      "1162/1162 [==============================] - 21s 18ms/step - loss: 1.0185 - categorical_accuracy: 0.6422 - val_loss: 1.1627 - val_categorical_accuracy: 0.6075\n",
      "Epoch 13/30\n",
      "1162/1162 [==============================] - 7s 6ms/step - loss: 0.9878 - categorical_accuracy: 0.6521 - val_loss: 1.1762 - val_categorical_accuracy: 0.6020\n",
      "Epoch 14/30\n",
      "1146/1162 [============================>.] - ETA: 0s - loss: 0.9675 - categorical_accuracy: 0.6605INFO:tensorflow:Assets written to: ./output/2023_07_26_22_08_11/saved_models/assets\n",
      "1162/1162 [==============================] - 8s 7ms/step - loss: 0.9679 - categorical_accuracy: 0.6606 - val_loss: 1.1927 - val_categorical_accuracy: 0.6130\n",
      "Epoch 15/30\n",
      "1162/1162 [==============================] - 8s 7ms/step - loss: 0.9538 - categorical_accuracy: 0.6653 - val_loss: 1.2353 - val_categorical_accuracy: 0.5887\n",
      "Epoch 16/30\n",
      "1154/1162 [============================>.] - ETA: 0s - loss: 0.9345 - categorical_accuracy: 0.6744INFO:tensorflow:Assets written to: ./output/2023_07_26_22_08_11/saved_models/assets\n",
      "1162/1162 [==============================] - 8s 7ms/step - loss: 0.9336 - categorical_accuracy: 0.6747 - val_loss: 1.1537 - val_categorical_accuracy: 0.6303\n",
      "Epoch 17/30\n",
      "1162/1162 [==============================] - 8s 7ms/step - loss: 0.9130 - categorical_accuracy: 0.6794 - val_loss: 1.1937 - val_categorical_accuracy: 0.6108\n",
      "Epoch 18/30\n",
      " 784/1162 [===================>..........] - ETA: 1s - loss: 0.9129 - categorical_accuracy: 0.6791"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax val val_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmax(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/tutorial_kws/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tutorial_kws/lib/python3.9/site-packages/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1389\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1391\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tutorial_kws/lib/python3.9/site-packages/keras/callbacks.py:430\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_hook(ModeKeys\u001b[38;5;241m.\u001b[39mTRAIN, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m'\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39mlogs)\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    431\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m      batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m      logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_data[0], y=train_data[1], \n",
    "                    steps_per_epoch=int(np.floor(len(train_data[0]) / batch_size)),\n",
    "                    epochs=n_epochs, \n",
    "                    callbacks=get_callbacks(output_dir, val_data, model, patience=patience), \n",
    "                    validation_data=val_data, \n",
    "                    shuffle=False)\n",
    "\n",
    "print('max val val_categorical_accuracy', np.max(history.history['val_categorical_accuracy']))\n",
    "\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db69659",
   "metadata": {
    "id": "painted-kidney"
   },
   "source": [
    "## Exercise\n",
    "1. We should see a significant difference between the training and validation accuracies in the plots above. Why is this the case?\n",
    "\n",
    "2. How do you judge the overall accuracy? Play with the number of hidden layers and the number of neurons in the hidden layers and retrain. Do you get a better result?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7721a6d6",
   "metadata": {},
   "source": [
    "## Hints\n",
    "1. Whats the difference between validation and train data?\n",
    "2. Look at the confusion matrices we have dumped to your data folder. What can you see? Also, hust copy the code you already have from above and change some parameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab802947",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954afb41",
   "metadata": {},
   "source": [
    "### E1\n",
    "The validation data are not used for parameter optimization. The phenomenon we encountered is called overfitting and it can have different causes like **data sparsity**, **outliers**, too many **degrees of freedom** etc. We will learn more about it in the next lecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1755130b",
   "metadata": {},
   "source": [
    "### E2\n",
    "The confusion matrices show that some keywords get mixed up a lot. The accuracy tells us how many instances are classified correctly or how many keywords are recognized correctly. <br>\n",
    "<br>\n",
    "**Lets try some deeper architectures**,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d11fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(name='input_layer', shape=(n_max_frames, n_mfccs)),\n",
    "        layers.Reshape((n_max_frames * n_mfccs, ), input_shape=(n_max_frames, n_mfccs)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),    \n",
    "        layers.Dense(n_output_neurons, activation='softmax'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23fb9dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_1 (Reshape)         (None, 1960)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                125504    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,396\n",
      "Trainable params: 168,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99d55592",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy()],\n",
    "              run_eagerly=debugging_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "986f34dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging to:  ./output/2023_07_26_22_11_48/\n",
      "Epoch 1/30\n",
      "1117/1162 [===========================>..] - ETA: 0s - loss: 1.8127 - categorical_accuracy: 0.4848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_data[0], y=train_data[1], \n",
    "                    steps_per_epoch=int(np.floor(len(train_data[0]) / batch_size)),\n",
    "                    epochs=n_epochs, \n",
    "                    callbacks=get_callbacks(output_dir, val_data, model, patience=patience), \n",
    "                    validation_data=val_data, \n",
    "                    shuffle=False)\n",
    "\n",
    "print('max val val_categorical_accuracy', np.max(history.history['val_categorical_accuracy']))\n",
    "\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9603d0",
   "metadata": {},
   "source": [
    "We can see that improving the network's depth helped to increase the accuracy to $74\\%$, so our model was not powerful enough so far. <br>\n",
    "<br>\n",
    "**Lets try more deeper model**, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "917ec5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(name='input_layer', shape=(n_max_frames, n_mfccs)),\n",
    "        layers.Reshape((n_max_frames * n_mfccs, ), input_shape=(n_max_frames, n_mfccs)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),    \n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(256, activation='relu'),    \n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(n_output_neurons, activation='softmax'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48d2aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy()],\n",
    "              run_eagerly=debugging_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "798c78ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_2 (Reshape)         (None, 1960)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                125504    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 12)                3084      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 564,684\n",
      "Trainable params: 564,684\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e06731f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging to:  ./output/2023_07_26_22_12_01/\n",
      "Epoch 1/30\n",
      " 246/1162 [=====>........................] - ETA: 10s - loss: 1.9919 - categorical_accuracy: 0.2942"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax val val_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmax(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_categorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/tutorial_kws/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tutorial_kws/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tutorial_kws/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tutorial_kws/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tutorial_kws/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tutorial_kws/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tutorial_kws/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tutorial_kws/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/tutorial_kws/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_data[0], y=train_data[1], \n",
    "                    steps_per_epoch=int(np.floor(len(train_data[0]) / batch_size)),\n",
    "                    epochs=n_epochs, \n",
    "                    callbacks=get_callbacks(output_dir, val_data, model, patience=patience), \n",
    "                    validation_data=val_data, \n",
    "                    shuffle=False)\n",
    "\n",
    "print('max val val_categorical_accuracy', np.max(history.history['val_categorical_accuracy']))\n",
    "\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b85fc",
   "metadata": {},
   "source": [
    "We see that a deeper model can help to increase the accuracy, however only up to a point. After that, adding parameters might not help anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595f648",
   "metadata": {},
   "source": [
    "Ideally we would like over $90\\%$, so we have some room for improvement :-)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "8aab069b"
   ],
   "name": "Kopie von 00_all_in_one_kws.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
